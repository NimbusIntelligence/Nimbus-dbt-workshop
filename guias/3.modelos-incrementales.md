# Modelos Incrementales

1. Crea un nuevo archivo llamado fetch_weather.sql en la carpeta macros ("/macros/fetch_weather.sql").

2. copia/pega el siguiente en fetch_weather.sql.

   ```sql
   {% macro fetch_weather() %}
       {% do run_query("CALL DBT_COURSE.WEATHER.DBT_FETCH_WEATHER('"+ target.schema +"');")%}
   {% endmacro %}
   ```

   Esto ejecuta el procedimiento dbt_fetch_weather() y genera su tabla en el esquema en el que estamos trabajando.

3. Crea una nueva carpeta en el directorio models llamada office_weather ("/models/office_weather").

4. Crea un archivo schema.yml en el directorio office_weather ("/models/office_weather/schema.yml") y copia/pega en él el YAML del archivo inicial schema.yml.

   ```yml
   version: 2

   sources:
     - name: office_weather
       schema: "{{target.schema}}"
       tables:
         - name: weather_readings

   models:
     - name: stg_weather_data
   ```

5. Crea stg_weather_data.sql en el directorio office_weather ("/models/office_weather/stg_weather_data.sql").

6. En stg_weather_data.sql ("/models/office_weather/stg_weather_data.sql") escribe la siguiente consulta para preparar nuestros datos fuente weather_reading.

   ```SQL
   select *
   from {{ source('office_weather', 'weather_readings') }}
   ```

7. Actualiza el archivo schema.yml ("/models/office_weather/schema.yml") para agregar un bloque config con un pre-hook que ejecute el macro fetch_weather() antes de que se ejecute el modelo stg_weather_data.

   ```yml
   version: 2

   sources:
     - name: office_weather
       schema: "{{target.schema}}"
       tables:
         - name: weather_readings

   models:
     - name: stg_weather_data
       config:
         pre_hook:
           - "{{ fetch_weather() }}"
   ```

8. Actualiza el archivo dbt_project.yml ("/dbt_project.yml") para materializar todo lo de la carpeta office_weather como una vista por defecto.

   ```yml
   models:
     my_new_project:
       # Applies to all files under models/example/
       example:
         +materialized: table

       lego:
         +materialized: table

       library_loans:
         +materialized: table

       office_weather:
         +materialized: view
   ```

   <details>
   <summary>full dbt_project.yml</summary>

   ```yml
   # Name your project! Project names should contain only lowercase characters
   # and underscores. A good package name should reflect your organization's
   # name or the intended use of these models
   name: "my_new_project"
   version: "1.0.0"
   config-version: 2

   # This setting configures which "profile" dbt uses for this project.
   profile: "default"

   # These configurations specify where dbt should look for different types of files.
   # The `model-paths` config, for example, states that models in this project can be
   # found in the "models/" directory. You probably won't need to change these!
   model-paths: ["models"]
   analysis-paths: ["analyses"]
   test-paths: ["tests"]
   seed-paths: ["seeds"]
   macro-paths: ["macros"]
   snapshot-paths: ["snapshots"]

   target-path: "target" # directory which will store compiled SQL files
   clean-targets: # directories to be removed by `dbt clean`
     - "target"
     - "dbt_packages"

   # Configuring models
   # Full documentation: https://docs.getdbt.com/docs/configuring-models

   # In dbt, the default materialization for a model is a view. This means, when you run
   # dbt run or dbt build, all of your models will be built as a view in your data platform.
   # The configuration below will override this setting for models in the example folder to
   # instead be materialized as tables. Any models you add to the root of the models folder will
   # continue to be built as views. These settings can be overridden in the individual model files
   # using the `{{ config(...) }}` macro.

   models:
     my_new_project:
       # Applies to all files under models/example/
       example:
         +materialized: table

       lego:
         +materialized: table

       library_loans:
         +materialized: table

       office_weather:
         +materialized: view
   ```

   </details>

9. En la barra de comandos, ejecuta el comando.

   ```sh
   dbt build --select office_weather
   ```

   Para ejecutar nuestro macro y luego crear nuestro modelo de staging en el data warehouse.

10. Crea un nuevo archivo dentro del directorio office_weather llamado all_weather_data.sql ("/models/office_weather/all_weather_data.sql").

11. Actualiza all_weather_data.sql ("/models/office_weather/all_weather_data.sql") para seleccionar desde el modelo stg_weather_data.

    ```sql
    select *
    from {{ ref('stg_weather_data') }}
    ```

12. Configura all_weather_data.sql ("/models/office_weather/all_weather_data.sql") como un modelo incremental agregando un bloque config al inicio del archivo. Especifica que la combinación de office y time es lo que define la unicidad.

    ```sql
    {{
        config(
            materialized='incremental',
            unique_key=['office','time']
        )
    }}
    select *
    from {{ ref('stg_weather_data') }}
    ```

13. Actualiza all_weather_data.sql ("/models/office_weather/all_weather_data.sql") para incluir un bloque is_incremental que compare el campo time con el valor máximo del campo time de su estado previo.

    ```sql
    {{
        config(
            materialized='incremental',
            unique_key=['office','time']
        )
    }}
    select *
    from {{ ref('stg_weather_data') }}

    {% if is_incremental() %}
        -- this filter will only be applied on an incremental run
        where time > (select max(time) from {{ this }})
    {% endif %}
    ```

14. En la barra de comandos, ejecuta el comando.

    ```sh
    dbt build --select office_weather
    ```

    Para construir todos nuestros modelos de office_weather. Tanto stg_weather_data como all_weather_data deberían ser generados.

15. En la barra de comandos, ejecuta el comando.

    ```sh
    dbt build --select all_weather_data
    ```

    Para crear el modelo all_weather_data en el data warehouse. Deberías ver la cláusula incremental presente en los logs.

16. En la barra de comandos, ejecuta el comando.

    ```sh
    dbt build --select all_weather_data --full-refresh
    ```

    Para crear el modelo all_weather_data en el data warehouse. Ahora no deberías ver la cláusula incremental en los logs.

### [Lista de Guias](../ReadMe.md)